{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHruMD4v5XFxkir7ZBnvV3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kwonsungja/autumn2024/blob/main/app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # Upload a CSV file manually\n",
        "df = pd.read_csv('nouns.csv')  # Replace 'your_file.csv' with the file name\n",
        "print(df.head())  # Show the first few rows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "LG4vAVZmFXSn",
        "outputId": "ee9cff70-ac18-4461-f50d-732fea12f9ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-09b54b62-4c1f-46cf-9373-0dd73af2f813\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-09b54b62-4c1f-46cf-9373-0dd73af2f813\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving nouns.csv to nouns (6).csv\n",
            "   0    Singular      Plural  Difficulty Level\n",
            "0  1       sheep       sheep                 1\n",
            "1  2        deer        deer                 1\n",
            "2  3   offspring   offspring                 1\n",
            "3  4  crossroads  crossroads                 1\n",
            "4  5         man         men                 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"NounSmart\")\n",
        "print (\"Basic rules for forming regular plural nouns.\")\n",
        "print (\"Add –s to the singular noun.\") #-s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtOD32aXJsqh",
        "outputId": "25cf0406-aeb4-4bd5-a3aa-119042db44aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NounSmart\n",
            "Basic rules for forming regular plural nouns.\n",
            "Add –s to the singular noun.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_s_to_nouns(nouns):\n",
        "    # 모든 명사에 '-s'를 추가하여 복수형으로 변환합니다.\n",
        "    return [noun + 's' for noun in nouns]\n",
        "\n",
        "# 단수 명사 리스트\n",
        "singular_nouns = [\"plane\", \"apple\", \"book\", \"house\", \"computer\", \"chair\", \"dog\", \"tree\"]\n",
        "\n",
        "# '-s'가 추가된 복수형 명사 리스트\n",
        "plural_nouns = add_s_to_nouns(singular_nouns)\n",
        "print(\"Singular Nouns:\", singular_nouns)\n",
        "print(\"Nouns with -s added:\", plural_nouns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DZkgzKmLx1f",
        "outputId": "dd02e9ff-b34d-4b07-c516-9ce59bfec5ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Singular Nouns: ['plane', 'apple', 'book', 'house', 'computer', 'chair', 'dog', 'tree']\n",
            "Nouns with -s added: ['planes', 'apples', 'books', 'houses', 'computers', 'chairs', 'dogs', 'trees']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Add –es to nouns ending in –s, -ss, -sh, -ch, -x, or –z.\")  #-es\n",
        "def pluralize_noun(noun):\n",
        "    # 명사가 특정 문자로 끝나면 '-es'를 추가하여 복수형을 만듭니다.\n",
        "    if noun.endswith(('s', 'ss', 'sh', 'ch', 'x', 'z')):\n",
        "        return noun + 'es'\n",
        "    else:\n",
        "        return noun + 's'  # 일반적인 경우에는 '-s'를 추가합니다.\n",
        "\n",
        "# 테스트할 명사 리스트\n",
        "nouns = [\"bus\", \"class\", \"dish\", \"church\", \"box\", \"fox\", \"match\", \"kiss\", \"car\", \"tree\"]\n",
        "\n",
        "# 각 명사를 복수형으로 변환\n",
        "plural_nouns = [pluralize_noun(noun) for noun in nouns]\n",
        "\n",
        "print(\"Singular Nouns:\", nouns)\n",
        "print(\"Plural Nouns:\", plural_nouns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmDWAyf7NWis",
        "outputId": "d529f969-b082-4d44-a916-ea80ac818967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Add –esto nouns ending in –s, -ss, -sh, -ch, -x, or –z.\n",
            "Singular Nouns: ['bus', 'class', 'dish', 'church', 'box', 'fox', 'match', 'kiss', 'car', 'tree']\n",
            "Plural Nouns: ['buses', 'classes', 'dishes', 'churches', 'boxes', 'foxes', 'matches', 'kisses', 'cars', 'trees']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Write the plural form of each noun. (-ies)\")   #-ies\n",
        "def convert_to_plural_ies(nouns):\n",
        "    # 각 명사에 대해 '-y'를 '-ies'로 변환하여 복수형으로 만듭니다.\n",
        "    plural_nouns = []\n",
        "    for noun in nouns:\n",
        "        if noun.endswith('y') and len(noun) > 1 and noun[-2] not in 'aeiou':\n",
        "            # '-y'를 '-ies'로 바꿔 복수형을 만듭니다.\n",
        "            plural_nouns.append(noun[:-1] + 'ies')\n",
        "        else:\n",
        "            # 일반적인 경우에는 '-s'를 추가합니다.\n",
        "            plural_nouns.append(noun + 's')\n",
        "    return plural_nouns\n",
        "\n",
        "# 단수 명사 리스트\n",
        "singular_nouns = [\"baby\", \"city\", \"lady\", \"party\", \"story\", \"puppy\", \"berry\", \"family\"]\n",
        "\n",
        "# '-ies'로 변환된 복수형 명사 리스트\n",
        "plural_nouns = convert_to_plural_ies(singular_nouns)\n",
        "\n",
        "print(\"Singular Nouns:\", singular_nouns)\n",
        "print(\"Plural Nouns with -ies added:\", plural_nouns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "380axrmZRAqc",
        "outputId": "a1776a47-3de4-4f69-a399-0d02168c421b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Write the plural form of each noun. (-ies)\n",
            "Singular Nouns: ['baby', 'city', 'lady', 'party', 'story', 'puppy', 'berry', 'family']\n",
            "Plural Nouns with -ies added: ['babies', 'cities', 'ladies', 'parties', 'stories', 'puppies', 'berries', 'families']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Write the plural form of each noun. (–es)\") # o로 끝나는 명사다음에 -es\n",
        "def convert_to_plural_es(nouns):\n",
        "    # 각 명사에 대해 'o'로 끝나는 경우 '-es'를 붙여 복수형으로 만듭니다.\n",
        "    plural_nouns = []\n",
        "    for noun in nouns:\n",
        "        if noun.endswith('o') and len(noun) > 1 and noun[-2] not in 'aeiou':\n",
        "            # 'o'로 끝나고 그 앞에 자음이 있는 경우 '-es'를 붙입니다.\n",
        "            plural_nouns.append(noun + 'es')\n",
        "        else:\n",
        "            # 일반적인 경우에는 '-s'를 추가합니다.\n",
        "            plural_nouns.append(noun + 's')\n",
        "    return plural_nouns\n",
        "\n",
        "# 단수 명사 리스트\n",
        "singular_nouns = [\"tomato\", \"hero\", \"potato\", \"echo\", \"veto\", \"tornado\", \"mosquito\", \"volcano\"]\n",
        "\n",
        "# '-es'로 변환된 복수형 명사 리스트\n",
        "plural_nouns = convert_to_plural_es(singular_nouns)\n",
        "\n",
        "print(\"Singular Nouns:\", singular_nouns)\n",
        "print(\"Plural Nouns with -es added:\", plural_nouns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DOCm5RgSiyf",
        "outputId": "585e844f-894e-4c2f-840b-6dd09c363745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Write the plural form of each noun. (–es)\n",
            "Singular Nouns: ['tomato', 'hero', 'potato', 'echo', 'veto', 'tornado', 'mosquito', 'volcano']\n",
            "Plural Nouns with -es added: ['tomatoes', 'heroes', 'potatoes', 'echoes', 'vetoes', 'tornadoes', 'mosquitoes', 'volcanoes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Write the plural form of each noun.\")   # 무작위로 명사가 주어졌을때\n",
        "def pluralize_irregular_nouns(nouns):\n",
        "    # 불규칙 명사의 복수형을 정의한 사전\n",
        "    irregular_nouns = {\n",
        "        \"sheep\": \"sheep\",\n",
        "        \"child\": \"children\",\n",
        "        \"wolf\": \"wolves\",\n",
        "        \"man\": \"men\",\n",
        "        \"deer\": \"deer\",\n",
        "        \"goose\": \"geese\",\n",
        "        \"series\": \"series\",\n",
        "        \"leaf\": \"leaves\"\n",
        "    }\n",
        "\n",
        "    plural_nouns = []\n",
        "    for noun in nouns:\n",
        "        # 불규칙 명사일 경우 사전에서 복수형을 찾습니다.\n",
        "        if noun in irregular_nouns:\n",
        "            plural_nouns.append(irregular_nouns[noun])\n",
        "        else:\n",
        "            # 규칙 명사일 경우 기본적으로 '-s'를 추가합니다.\n",
        "            plural_nouns.append(noun + 's')\n",
        "\n",
        "    return plural_nouns\n",
        "\n",
        "# 단수 명사 리스트\n",
        "singular_nouns = [\"sheep\", \"child\", \"wolf\", \"man\", \"deer\", \"goose\", \"series\", \"leaf\"]\n",
        "\n",
        "# 복수형 명사 리스트\n",
        "plural_nouns = pluralize_irregular_nouns(singular_nouns)\n",
        "\n",
        "print(\"Singular Nouns:\", singular_nouns)\n",
        "print(\"Plural Nouns:\", plural_nouns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_0COzKgUgfY",
        "outputId": "a6286cfb-ebf9-4cbc-bb45-60bca66ca69f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Write the plural form of each noun.\n",
            "Singular Nouns: ['sheep', 'child', 'wolf', 'man', 'deer', 'goose', 'series', 'leaf']\n",
            "Plural Nouns: ['sheep', 'children', 'wolves', 'men', 'deer', 'geese', 'series', 'leaves']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"the right form to fit the determiner before the blank.\")   # 한정사에 맞는 명사작성\n",
        "def pluralize(noun):\n",
        "    \"\"\"Simple pluralization logic.\"\"\"\n",
        "    if noun.endswith(('s', 'ss', 'sh', 'ch', 'x', 'z')):\n",
        "        return noun + 'es'\n",
        "    elif noun.endswith('y') and noun[-2] not in 'aeiou':\n",
        "        return noun[:-1] + 'ies'\n",
        "    elif noun.endswith('o') and noun[-2] not in 'aeiou':\n",
        "        return noun + 'es'\n",
        "    else:\n",
        "        return noun + 's'\n",
        "\n",
        "def determine_noun_form(determiner, noun):\n",
        "    singular_determiners = ['a', 'an', 'each', 'every', 'another', 'this', 'that']\n",
        "    plural_determiners = ['these', 'those', 'both', 'several', 'many', 'much']\n",
        "\n",
        "    if determiner in singular_determiners:\n",
        "        return f\"{determiner} {noun}\"\n",
        "    elif determiner in plural_determiners:\n",
        "        plural_noun = pluralize(noun)\n",
        "        return f\"{determiner} {plural_noun}\"\n",
        "    else:\n",
        "        raise ValueError(\"Determiner not recognized\")\n",
        "\n",
        "# Test examples\n",
        "nouns = [\"city\", \"bus\", \"child\", \"man\"]\n",
        "determiners = [\"several\", \"every\", \"both\", \"another\"]\n",
        "\n",
        "for noun in nouns:\n",
        "    for determiner in determiners:\n",
        "        try:\n",
        "            result = determine_noun_form(determiner, noun)\n",
        "            print(result)\n",
        "        except ValueError as e:\n",
        "            print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnSU17CEWZBl",
        "outputId": "458d34bb-227a-4250-fcd5-2aaeb63b22e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the right form to fit the determiner before the blank.\n",
            "several cities\n",
            "every city\n",
            "both cities\n",
            "another city\n",
            "several buses\n",
            "every bus\n",
            "both buses\n",
            "another bus\n",
            "several childs\n",
            "every child\n",
            "both childs\n",
            "another child\n",
            "several mans\n",
            "every man\n",
            "both mans\n",
            "another man\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Fill in the blank with the appropriate form.\")   #적절한 명사형태 적기\n",
        "def pluralize(noun):\n",
        "    \"\"\"Convert a singular noun to its plural form.\"\"\"\n",
        "    if noun.endswith(('s', 'ss', 'sh', 'ch', 'x', 'z')):\n",
        "        return noun + 'es'\n",
        "    elif noun.endswith('y') and noun[-2] not in 'aeiou':\n",
        "        return noun[:-1] + 'ies'\n",
        "    elif noun.endswith('o') and noun[-2] not in 'aeiou':\n",
        "        return noun + 'es'\n",
        "    else:\n",
        "        return noun + 's'\n",
        "\n",
        "def suggest_noun_form(verb_phrase, noun):\n",
        "    \"\"\"Suggest the noun form based on the verb phrase.\"\"\"\n",
        "    # Check if the verb phrase indicates plural\n",
        "    if 'were' in verb_phrase or 'are' in verb_phrase:\n",
        "        return pluralize(noun)\n",
        "    elif 'was' in verb_phrase or 'is' in verb_phrase:\n",
        "        return noun\n",
        "    else:\n",
        "        raise ValueError(\"Verb phrase not recognized or unsupported verb form\")\n",
        "\n",
        "# Example usage\n",
        "sentence = \"______ were laid down on the blanket.\"\n",
        "given_noun = \"baby\"\n",
        "\n",
        "try:\n",
        "    correct_noun_form = suggest_noun_form(sentence, given_noun)\n",
        "    print(f\"The correct noun form for the sentence is: {correct_noun_form}\")\n",
        "except ValueError as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkyUbizWZMBx",
        "outputId": "37219ce6-9382-455e-b0c8-83c3de9271ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fill in the blank with the appropriate form.\n",
            "The correct noun form for the sentence is: babies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install gradio\n",
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcRZjBTPDCPG",
        "outputId": "8b6f4f97-258c-4456-a644-04382aa5337f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.6.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.3 (from gradio)\n",
            "  Downloading gradio_client-1.4.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart==0.0.12 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.8.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<1.0,>=0.1.1 (from gradio)\n",
            "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.3->gradio) (2024.10.0)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.3->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.6.0-py3-none-any.whl (57.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.3-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading ruff-0.8.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.5 ffmpy-0.4.0 gradio-5.6.0 gradio-client-1.4.3 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.12 ruff-0.8.0 safehttpx-0.1.1 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.12.0 uvicorn-0.32.1 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Define a function that takes user input and returns model predictions\n",
        "def greeting(Name):\n",
        "    # Your model prediction logic here\n",
        "    return \"Greeting: Hello, \" + Name + \"!\" + \"\\n\" + \"Nice to meet you. How can I help you today?\"\n",
        "\n",
        "# Create a Gradio interface\n",
        "iface = gr.Interface(fn=greeting, inputs=\"text\", outputs=\"text\")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "d20zd4sHDMXN",
        "outputId": "921c8cfe-0298-4814-9441-771eca80e84b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://2f96a6780953d7542a.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2f96a6780953d7542a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gradio as gr\n",
        "\n",
        "# Create a DataFrame with verb information\n",
        "data = {\n",
        "    'Regularity': ['Irregular', 'Irregular', 'Irregular', 'Irregular', 'Irregular', 'Regular', 'Regular', 'Regular', 'Regular', 'Regular'],\n",
        "    'Present': ['sing', 'go', 'come', 'see', 'take', 'walk', 'want', 'play', 'work', 'clean'],\n",
        "    'Past': ['sang', 'went', 'came', 'saw', 'took', 'walked', 'wanted', 'played', 'worked', 'cleaned'],\n",
        "    'PP': ['sung', 'gone', 'come', 'seen', 'taken', 'walked', 'wanted', 'played', 'worked', 'cleaned']\n",
        "}\n",
        "verbs_df = pd.DataFrame(data)\n",
        "\n",
        "# Function to generate a quiz question\n",
        "def generate_question():\n",
        "    idx = verbs_df.sample().index[0]  # Randomly sample one verb\n",
        "    question = verbs_df.loc[idx, 'Present']\n",
        "    answer = f\"{verbs_df.loc[idx, 'Present']}-{verbs_df.loc[idx, 'Past']}-{verbs_df.loc[idx, 'PP']}\"\n",
        "    return question, answer\n",
        "\n",
        "# Function to check the user's answer\n",
        "def check_answer(user_input, question, answer):\n",
        "    if user_input.strip().lower() == answer.lower():\n",
        "        feedback = \"Good job!\"\n",
        "        next_question, next_answer = generate_question()  # Fetch next question on correct answer\n",
        "    else:\n",
        "        feedback = \"Try again\"\n",
        "        next_question, next_answer = question, answer  # Repeat the same question on incorrect answer\n",
        "\n",
        "    return next_question, next_answer, feedback\n",
        "\n",
        "# Build the Gradio interface\n",
        "with gr.Blocks() as app:\n",
        "    with gr.Row():\n",
        "        question = gr.State(value=\"run\")  # Initialize with an easy example\n",
        "        answer = gr.State(value=\"run-ran-run\")  # Correct answer for initialization\n",
        "\n",
        "    question_label = gr.Textbox(label=\"Type the present, past, and past participle forms of the verb below, separated by hyphens (e.g., be-was/were-been):\", value=question.value, interactive=False)\n",
        "    user_input = gr.Textbox(label=\"Your Answer\")\n",
        "    submit_button = gr.Button(\"Submit\")\n",
        "    feedback_label = gr.Label(value=\"\")\n",
        "\n",
        "    # Logic to handle submission\n",
        "    submit_button.click(\n",
        "        fn=check_answer,\n",
        "        inputs=[user_input, question, answer],\n",
        "        outputs=[question_label, answer, feedback_label]\n",
        "    )\n",
        "\n",
        "app.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "TqY8ByWfDYKK",
        "outputId": "61e0e692-79d5-450c-965a-cfa1016b5226"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://349957ce400bf7d8f7.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://349957ce400bf7d8f7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gradio as gr\n",
        "\n",
        "# Create a DataFrame with noun information\n",
        "data = {\n",
        "    'singular_nouns': ['plane', 'apple', 'book', 'house', 'computer', 'chair', 'dog', 'tree'],\n",
        "    'plural_nouns': ['planes', 'apples', 'books', 'houses', 'computers', 'chairs', 'dogs', 'trees']\n",
        "}\n",
        "nouns_df = pd.DataFrame(data)\n",
        "\n",
        "# Function to generate a quiz question\n",
        "def generate_question():\n",
        "    idx = nouns_df.sample().index[0]  # Randomly sample one noun\n",
        "    question = nouns_df.loc[idx, 'singular_nouns']\n",
        "    answer = nouns_df.loc[idx, 'plural_nouns']\n",
        "    return question, answer\n",
        "\n",
        "# Function to check the user's answer\n",
        "def check_answer(user_input, question, answer):\n",
        "    if user_input.strip().lower() == answer.lower():\n",
        "        feedback = \"Good job!\"\n",
        "        next_question, next_answer = generate_question()  # Fetch next question on correct answer\n",
        "    else:\n",
        "        feedback = \"Try again\"\n",
        "        next_question, next_answer = question, answer  # Repeat the same question on incorrect answer\n",
        "\n",
        "    return next_question, next_answer, feedback\n",
        "\n",
        "# Build the Gradio interface\n",
        "with gr.Blocks() as app:\n",
        "    # Initialize with a random question\n",
        "    initial_question, initial_answer = generate_question()\n",
        "\n",
        "    question_label = gr.Textbox(label=\"What is the plural form of this noun?\", value=initial_question, interactive=False)\n",
        "    user_input = gr.Textbox(label=\"Your Answer\")\n",
        "    answer_hidden = gr.Textbox(value=initial_answer, visible=False)  # Hidden to keep track of the correct answer\n",
        "    submit_button = gr.Button(\"Submit\")\n",
        "    feedback_label = gr.Label(value=\"\")\n",
        "\n",
        "    # Logic to handle submission\n",
        "    submit_button.click(\n",
        "        fn=check_answer,\n",
        "        inputs=[user_input, question_label, answer_hidden],\n",
        "        outputs=[question_label, answer_hidden, feedback_label]\n",
        "    )\n",
        "\n",
        "app.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "htEzOe6fDnqg",
        "outputId": "f70e01c2-7897-47f7-cbee-004edcc17619"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c485c37f83168e315d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c485c37f83168e315d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gradio as gr\n",
        "\n",
        "# Create a DataFrame with noun information that form plurals by adding \"-es\"\n",
        "data = {\n",
        "    'singular_nouns': ['bus', 'class', 'dish', 'church', 'box', 'fox', 'match', 'kiss', 'car', 'tree'],\n",
        "    'plural_nouns': ['buses', 'classes', 'dishes', 'churches', 'boxes', 'foxes', 'matches', 'kisses', 'cars', 'trees']\n",
        "}\n",
        "nouns_df = pd.DataFrame(data)\n",
        "\n",
        "# Function to generate a quiz question\n",
        "def generate_question():\n",
        "    idx = nouns_df.sample().index[0]  # Randomly sample one noun\n",
        "    question = nouns_df.loc[idx, 'singular_nouns']\n",
        "    answer = nouns_df.loc[idx, 'plural_nouns']\n",
        "    return question, answer\n",
        "\n",
        "# Function to check the user's answer\n",
        "def check_answer(user_input, question, answer):\n",
        "    if user_input.strip().lower() == answer.lower():\n",
        "        feedback = \"Good job!\"\n",
        "        next_question, next_answer = generate_question()  # Fetch next question on correct answer\n",
        "    else:\n",
        "        feedback = \"Try again\"\n",
        "        next_question, next_answer = question, answer  # Repeat the same question on incorrect answer\n",
        "\n",
        "    return next_question, next_answer, feedback\n",
        "\n",
        "# Build the Gradio interface\n",
        "with gr.Blocks() as app:\n",
        "    # Initialize with a random question\n",
        "    initial_question, initial_answer = generate_question()\n",
        "\n",
        "    question_label = gr.Textbox(label=\"What is the plural form of this noun?\", value=initial_question, interactive=False)\n",
        "    user_input = gr.Textbox(label=\"Your Answer\")\n",
        "    answer_hidden = gr.Textbox(value=initial_answer, visible=False)  # Hidden to keep track of the correct answer\n",
        "    submit_button = gr.Button(\"Submit\")\n",
        "    feedback_label = gr.Label(value=\"\")\n",
        "\n",
        "    # Logic to handle submission\n",
        "    submit_button.click(\n",
        "        fn=check_answer,\n",
        "        inputs=[user_input, question_label, answer_hidden],\n",
        "        outputs=[question_label, answer_hidden, feedback_label]\n",
        "    )\n",
        "\n",
        "app.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "ArmBL85QMRdN",
        "outputId": "291abfc0-572a-44c1-f4a3-e1eee7771b34"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://ed71f0082498cd7228.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ed71f0082498cd7228.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gradio as gr\n",
        "\n",
        "# Create a DataFrame with nouns that form plurals by changing \"-y\" to \"-ies\"\n",
        "data = {\n",
        "    'singular_nouns': ['baby', 'city', 'lady', 'party', 'story', 'puppy', 'berry', 'family'],\n",
        "    'plural_nouns': ['babies', 'cities', 'ladies', 'parties', 'stories', 'puppies', 'berries', 'families']\n",
        "}\n",
        "nouns_df = pd.DataFrame(data)\n",
        "\n",
        "# Function to generate a quiz question\n",
        "def generate_question():\n",
        "    idx = nouns_df.sample().index[0]  # Randomly sample one noun\n",
        "    question = nouns_df.loc[idx, 'singular_nouns']\n",
        "    answer = nouns_df.loc[idx, 'plural_nouns']\n",
        "    return question, answer\n",
        "\n",
        "# Function to check the user's answer\n",
        "def check_answer(user_input, question, answer):\n",
        "    if user_input.strip().lower() == answer.lower():\n",
        "        feedback = \"Good job!\"\n",
        "        next_question, next_answer = generate_question()  # Fetch next question on correct answer\n",
        "    else:\n",
        "        feedback = \"Try again\"\n",
        "        next_question, next_answer = question, answer  # Repeat the same question on incorrect answer\n",
        "\n",
        "    return next_question, next_answer, feedback\n",
        "\n",
        "# Build the Gradio interface\n",
        "with gr.Blocks() as app:\n",
        "    # Initialize with a random question\n",
        "    initial_question, initial_answer = generate_question()\n",
        "\n",
        "    question_label = gr.Textbox(label=\"What is the plural form of this noun?\", value=initial_question, interactive=False)\n",
        "    user_input = gr.Textbox(label=\"Your Answer\")\n",
        "    answer_hidden = gr.Textbox(value=initial_answer, visible=False)  # Hidden to keep track of the correct answer\n",
        "    submit_button = gr.Button(\"Submit\")\n",
        "    feedback_label = gr.Label(value=\"\")\n",
        "\n",
        "    # Logic to handle submission\n",
        "    submit_button.click(\n",
        "        fn=check_answer,\n",
        "        inputs=[user_input, question_label, answer_hidden],\n",
        "        outputs=[question_label, answer_hidden, feedback_label]\n",
        "    )\n",
        "\n",
        "app.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "WModDD3WN8Qn",
        "outputId": "c2cb22d1-195c-4cb5-939e-9e6c90023e4e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://0de66c8656a0a637a6.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0de66c8656a0a637a6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gradio as gr\n",
        "\n",
        "# Create a DataFrame with nouns that form plurals by adding \"-es\" to words ending in \"-o\"\n",
        "data = {\n",
        "    'singular_nouns': ['tomato', 'hero', 'potato', 'echo', 'veto', 'tornado', 'mosquito', 'volcano'],\n",
        "    'plural_nouns': ['tomatoes', 'heroes', 'potatoes', 'echoes', 'vetoes', 'tornadoes', 'mosquitoes', 'volcanoes']\n",
        "}\n",
        "nouns_df = pd.DataFrame(data)\n",
        "\n",
        "# Function to generate a quiz question\n",
        "def generate_question():\n",
        "    idx = nouns_df.sample().index[0]  # Randomly sample one noun\n",
        "    question = nouns_df.loc[idx, 'singular_nouns']\n",
        "    answer = nouns_df.loc[idx, 'plural_nouns']\n",
        "    return question, answer\n",
        "\n",
        "# Function to check the user's answer\n",
        "def check_answer(user_input, question, answer):\n",
        "    if user_input.strip().lower() == answer.lower():\n",
        "        feedback = \"Good job!\"\n",
        "        next_question, next_answer = generate_question()  # Fetch next question on correct answer\n",
        "    else:\n",
        "        feedback = \"Try again\"\n",
        "        next_question, next_answer = question, answer  # Repeat the same question on incorrect answer\n",
        "\n",
        "    return next_question, next_answer, feedback\n",
        "\n",
        "# Build the Gradio interface\n",
        "with gr.Blocks() as app:\n",
        "    # Initialize with a random question\n",
        "    initial_question, initial_answer = generate_question()\n",
        "\n",
        "    question_label = gr.Textbox(label=\"What is the plural form of this noun?\", value=initial_question, interactive=False)\n",
        "    user_input = gr.Textbox(label=\"Your Answer\")\n",
        "    answer_hidden = gr.Textbox(value=initial_answer, visible=False)  # Hidden to keep track of the correct answer\n",
        "    submit_button = gr.Button(\"Submit\")\n",
        "    feedback_label = gr.Label(value=\"\")\n",
        "\n",
        "    # Logic to handle submission\n",
        "    submit_button.click(\n",
        "        fn=check_answer,\n",
        "        inputs=[user_input, question_label, answer_hidden],\n",
        "        outputs=[question_label, answer_hidden, feedback_label]\n",
        "    )\n",
        "\n",
        "app.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "ICzoN_a_OwGh",
        "outputId": "de9d3e7b-b72a-4c5c-cdc9-1b4b61483b3d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7f94cc398b97caf1fc.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7f94cc398b97caf1fc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gradio as gr\n",
        "\n",
        "# Create a DataFrame with nouns that have irregular plural forms\n",
        "data = {\n",
        "    'singular_nouns': ['sheep', 'child', 'wolf', 'man', 'deer', 'goose', 'series', 'leaf'],\n",
        "    'plural_nouns': ['sheep', 'children', 'wolves', 'men', 'deer', 'geese', 'series', 'leaves']\n",
        "}\n",
        "nouns_df = pd.DataFrame(data)\n",
        "\n",
        "# Function to generate a quiz question\n",
        "def generate_question():\n",
        "    idx = nouns_df.sample().index[0]  # Randomly sample one noun\n",
        "    question = nouns_df.loc[idx, 'singular_nouns']\n",
        "    answer = nouns_df.loc[idx, 'plural_nouns']\n",
        "    return question, answer\n",
        "\n",
        "# Function to check the user's answer\n",
        "def check_answer(user_input, question, answer):\n",
        "    if user_input.strip().lower() == answer.lower():\n",
        "        feedback = \"Good job!\"\n",
        "        next_question, next_answer = generate_question()  # Fetch next question on correct answer\n",
        "    else:\n",
        "        feedback = \"Try again\"\n",
        "        next_question, next_answer = question, answer  # Repeat the same question on incorrect answer\n",
        "\n",
        "    return next_question, next_answer, feedback\n",
        "\n",
        "# Build the Gradio interface\n",
        "with gr.Blocks() as app:\n",
        "    # Initialize with a random question\n",
        "    initial_question, initial_answer = generate_question()\n",
        "\n",
        "    question_label = gr.Textbox(label=\"What is the plural form of this noun?\", value=initial_question, interactive=False)\n",
        "    user_input = gr.Textbox(label=\"Your Answer\")\n",
        "    answer_hidden = gr.Textbox(value=initial_answer, visible=False)  # Hidden to keep track of the correct answer\n",
        "    submit_button = gr.Button(\"Submit\")\n",
        "    feedback_label = gr.Label(value=\"\")\n",
        "\n",
        "    # Logic to handle submission\n",
        "    submit_button.click(\n",
        "        fn=check_answer,\n",
        "        inputs=[user_input, question_label, answer_hidden],\n",
        "        outputs=[question_label, answer_hidden, feedback_label]\n",
        "    )\n",
        "\n",
        "app.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "B6empRngO6Yd",
        "outputId": "2a009ca8-fd02-4423-e23e-c34df5cfc1ec"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://43a57d5146a9c00e6d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://43a57d5146a9c00e6d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import random\n",
        "\n",
        "# Define the nouns\n",
        "nouns_data = {\n",
        "    'singular_nouns': ['city', 'dog', 'apple', 'book', 'lady'],\n",
        "    'plural_nouns': ['cities', 'dogs', 'apples', 'books', 'ladies'],\n",
        "}\n",
        "\n",
        "# Initialize score and question count\n",
        "score = 0\n",
        "question_count = 0\n",
        "\n",
        "# Function to generate a quiz question\n",
        "def generate_question():\n",
        "    idx = random.randint(0, len(nouns_data['singular_nouns']) - 1)  # Randomly select an index\n",
        "    singular_noun = nouns_data['singular_nouns'][idx]\n",
        "    plural_noun = nouns_data['plural_nouns'][idx]\n",
        "\n",
        "    # Determine the appropriate determiner for the singular noun\n",
        "    if singular_noun[0].lower() in 'aeiou':\n",
        "        singular_determiner = 'an'\n",
        "    else:\n",
        "        singular_determiner = 'a'\n",
        "\n",
        "    plural_determiner = 'several'\n",
        "\n",
        "    return singular_noun, plural_noun, singular_determiner, plural_determiner\n",
        "\n",
        "# Function to check the user's choice of determiner\n",
        "def check_determiner_choice(user_input, singular_noun, plural_noun):\n",
        "    global score, question_count\n",
        "\n",
        "    # Generate the correct determiners\n",
        "    if singular_noun[0].lower() in 'aeiou':\n",
        "        correct_singular_determiner = 'an'\n",
        "    else:\n",
        "        correct_singular_determiner = 'a'\n",
        "    correct_plural_determiner = 'several'\n",
        "\n",
        "    user_inputs = user_input.split(',')\n",
        "    if len(user_inputs) != 2:\n",
        "        return singular_noun, plural_noun, f\"Please enter 'a/an' and 'several', separated by a comma.\", score\n",
        "\n",
        "    singular_choice, plural_choice = user_inputs[0].strip().lower(), user_inputs[1].strip().lower()\n",
        "\n",
        "    if singular_choice == correct_singular_determiner and plural_choice == correct_plural_determiner:\n",
        "        score += 1\n",
        "        feedback = f\"Correct! '{singular_choice} {singular_noun}' and '{plural_choice} {plural_noun}' are appropriate.\"\n",
        "    else:\n",
        "        feedback = f\"Try again. '{correct_singular_determiner} {singular_noun}' and '{correct_plural_determiner} {plural_noun}' are appropriate.\"\n",
        "\n",
        "    question_count += 1\n",
        "\n",
        "    if question_count >= 10:\n",
        "        final_feedback = f\"Quiz completed! Your final score is {score} out of 10.\"\n",
        "        # Reset score and question count for a new session\n",
        "        score = 0\n",
        "        question_count = 0\n",
        "        next_singular_noun, next_plural_noun = generate_question()\n",
        "        return next_singular_noun, next_plural_noun, final_feedback, score\n",
        "\n",
        "    next_singular_noun, next_plural_noun, _, _ = generate_question()  # Fetch next question\n",
        "    return next_singular_noun, next_plural_noun, f\"{feedback}\", score\n",
        "\n",
        "# Build the Gradio interface\n",
        "with gr.Blocks() as app:\n",
        "    # Initialize with a random question\n",
        "    singular_noun, plural_noun, singular_determiner, plural_determiner = generate_question()\n",
        "\n",
        "    noun_label = gr.Textbox(label=\"Noun\", value=f\"{singular_noun} ({singular_determiner} {singular_noun}, {plural_determiner} {plural_noun})\", interactive=False)\n",
        "    user_input = gr.Textbox(label=\"Fill in the blank with the appropriate form.\")\n",
        "    submit_button = gr.Button(\"Submit\")\n",
        "    feedback_label = gr.Label(value=\"\")\n",
        "    score_label = gr.Label(value=f\"Score: {score}\")\n",
        "\n",
        "    # Logic to handle submission\n",
        "    submit_button.click(\n",
        "        fn=check_determiner_choice,\n",
        "        inputs=[user_input, noun_label],\n",
        "        outputs=[noun_label, feedback_label, score_label]\n",
        "    )\n",
        "\n",
        "app.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "id": "Nh5T7ugSPsAB",
        "outputId": "833cb623-4e04-4a25-ef6c-0efdaee38d1f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/utils.py:999: UserWarning: Expected 3 arguments for function <function check_determiner_choice at 0x7de15f2395a0>, received 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/utils.py:1003: UserWarning: Expected at least 3 arguments for function <function check_determiner_choice at 0x7de15f2395a0>, received 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5aea910184c1b8e827.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5aea910184c1b8e827.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import random\n",
        "\n",
        "# Define the nouns and example sentences\n",
        "nouns_data = {\n",
        "    'singular_nouns': ['baby', 'city', 'dog', 'apple', 'book', 'lady'],\n",
        "    'plural_nouns': ['babies', 'cities', 'dogs', 'apples', 'books', 'ladies'],\n",
        "}\n",
        "\n",
        "example_sentences = [\n",
        "    \"______ were laid down on the blanket.\",\n",
        "    \"In the distance, ______ could be seen.\",\n",
        "    \"The ______ were playing in the park.\",\n",
        "    \"______ are delicious this time of year.\",\n",
        "    \"All the ______ were neatly arranged on the shelf.\",\n",
        "    \"The ______ danced gracefully across the stage.\"\n",
        "]\n",
        "\n",
        "# Initialize score and question count\n",
        "score = 0\n",
        "question_count = 0\n",
        "\n",
        "# Function to generate a quiz question\n",
        "def generate_question():\n",
        "    idx = random.randint(0, len(nouns_data['singular_nouns']) - 1)  # Randomly select an index\n",
        "    singular_noun = nouns_data['singular_nouns'][idx]\n",
        "    plural_noun = nouns_data['plural_nouns'][idx]\n",
        "    sentence = random.choice(example_sentences)\n",
        "    return singular_noun, plural_noun, sentence\n",
        "\n",
        "# Function to check the user's choice of noun form\n",
        "def check_noun_choice(user_input, plural_noun, sentence):\n",
        "    global score, question_count\n",
        "\n",
        "    if user_input.strip().lower() == plural_noun:\n",
        "        score += 1\n",
        "        feedback = f\"Correct! '{plural_noun}' fits the sentence: {sentence.replace('______', plural_noun)}\"\n",
        "    else:\n",
        "        feedback = f\"Try again. The correct plural form is '{plural_noun}'.\"\n",
        "\n",
        "    question_count += 1\n",
        "\n",
        "    if question_count >= 10:\n",
        "        final_feedback = f\"Quiz completed! Your final score is {score} out of 10.\"\n",
        "        # Reset score and question count for a new session\n",
        "        score = 0\n",
        "        question_count = 0\n",
        "        next_singular_noun, next_plural_noun, next_sentence = generate_question()\n",
        "        return next_plural_noun, next_sentence, final_feedback, score\n",
        "\n",
        "    next_singular_noun, next_plural_noun, next_sentence = generate_question()  # Fetch next question\n",
        "    return next_plural_noun, next_sentence, f\"{feedback}\", score\n",
        "\n",
        "# Build the Gradio interface\n",
        "with gr.Blocks() as app:\n",
        "    # Initialize with a random question\n",
        "    singular_noun, plural_noun, sentence = generate_question()\n",
        "\n",
        "    sentence_display = gr.Textbox(label=\"Sentence\", value=sentence, interactive=False)\n",
        "    user_input = gr.Textbox(label=\"Fill in the blank with the plural form of the noun\")\n",
        "    submit_button = gr.Button(\"Submit\")\n",
        "    feedback_label = gr.Label(value=\"\")\n",
        "    score_label = gr.Label(value=f\"Score: {score}\")\n",
        "\n",
        "    # Logic to handle submission\n",
        "    submit_button.click(\n",
        "        fn=check_noun_choice,\n",
        "        inputs=[user_input, plural_noun, sentence],\n",
        "        outputs=[sentence_display, feedback_label, score_label]\n",
        "    )\n",
        "\n",
        "app.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "saTmMR4QXtbU",
        "outputId": "324a0f40-ba73-444e-978e-a78b4d98126a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute '_id'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-7c421138e181>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# Logic to handle submission\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     submit_button.click(\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_noun_choice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplural_noun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/events.py\u001b[0m in \u001b[0;36mevent_trigger\u001b[0;34m(block, fn, inputs, outputs, api_name, scroll_to_output, show_progress, queue, batch, max_batch_size, preprocess, postprocess, cancels, trigger_mode, js, concurrency_limit, concurrency_id, show_api, time_limit, stream_every, like_user_message)\u001b[0m\n\u001b[1;32m    639\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_callback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0m_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mDependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdep_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0mevent_trigger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_event_name\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;34m\"id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0;34m\"targets\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m             \u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m             \u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;34m\"backend_fn\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;34m\"id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0;34m\"targets\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m             \u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m             \u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;34m\"backend_fn\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute '_id'"
          ]
        }
      ]
    }
  ]
}